{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from metrics.ipynb\n",
      "importing Jupyter notebook from data_transformation.ipynb\n",
      "importing Jupyter notebook from train_validation.ipynb\n",
      "importing Jupyter notebook from model_architecture.ipynb\n",
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "from torch import nn \n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import import_ipynb\n",
    "import metrics\n",
    "import data_transformation\n",
    "import train_validation\n",
    "import model_architecture\n",
    "import utils\n",
    "import unittest\n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_modules(module_test):\n",
    "    \"\"\"Run unittest in imported files\"\"\"\n",
    "    \n",
    "    suite = unittest.TestLoader().loadTestsFromModule(module_test)\n",
    "    unittest.TextTestRunner(verbosity=1).run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 23.866s\n",
      "\n",
      "OK\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.006s\n",
      "\n",
      "OK\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.114s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "testmodules = [data_transformation.data_class_test(), metrics.metrics_test(), utils.utils_test()]\n",
    "for test in testmodules:\n",
    "    test_modules(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'save_model_path': \"test.chkpt\",\n",
    "    'epoch': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11705, 2, 34, 20)\n",
      "Model parameters: 219675\n",
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "data_class = data_transformation.data_transformation(path_data = \"/data/data_curated_20180219/curated_training_data_no_mass_spec.csv\",\n",
    "                                                     path_mhc = \"/data/aligned_mhc_dataset.csv\",\n",
    "                                                     allele_name = \"HLA-A*02:01\",\n",
    "                                                     quant_data = True,\n",
    "                                                     encoding = \"one-hot\")\n",
    "\n",
    "pep, mhc, target = data_class.__getitem__()\n",
    "\n",
    "pep = np.expand_dims(pep, axis=1)\n",
    "mhc = np.expand_dims(mhc, axis=1)\n",
    "inp = np.hstack((pep, mhc))\n",
    "print(inp.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inp, target.T, test_size=0.2, random_state=42)\n",
    "\n",
    "model = model_architecture.convnet(inputchannel = np.size(X_train, 3),\n",
    "                                   L = np.size(X_train, 2))\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Model parameters: \" + str(pytorch_total_params) )\n",
    "if torch.cuda.device_count() > 0:\n",
    "    print('Using GPU' + str(utils.pick_gpu_lowest_memory()))\n",
    "    device = torch.device('cuda:' + str(utils.pick_gpu_lowest_memory()))\n",
    "else:\n",
    "    print('Using CPU')\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "model = model.to(device)\n",
    "criterion = metrics.select_criterion('MSE')\n",
    "optimizer = optim.Adam(\n",
    "        filter(lambda x: x.requires_grad, model.parameters()),\n",
    "        betas=(0.9, 0.98), eps=1e-09, weight_decay = 0.0)\n",
    "\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train))\n",
    "test_data = torch.utils.data.TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
    "                              batch_size = params['batch_size'],\n",
    "                              shuffle = True, \n",
    "                              drop_last = True)\n",
    "eval_dataloader = torch.utils.data.DataLoader(test_data,\n",
    "                              batch_size = params['batch_size'],\n",
    "                              shuffle = True,\n",
    "                              drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch 0 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  - (Training)   :  12%|███████▋                                                      | 36/292 [00:58<07:01,  1.65s/it]"
     ]
    }
   ],
   "source": [
    "valid_losss, train_losses, valid_accus, train_accus = train_validation.start_training(params['save_model_path'], params['epoch'], model,\n",
    "                                                                                      train_dataloader, eval_dataloader, optimizer,\n",
    "                                                                                      device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint found and loaded - Resuming training\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training)   ppl: 0.14249686151742935, Accuracy: 0.20002837834907883, elapse: 0.18731647729873657 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Validation) ppl: 0.10182568430900574, Accuracy: -0.05117330838421105, elapse: 0.012834278742472331 min\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training)   ppl: 0.10645390748977661, Accuracy: 0.31931252712171926, elapse: 0.22762589454650878 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Validation) ppl: 0.08408648520708084, Accuracy: 0.10670699137871208, elapse: 0.019465947151184083 min\n"
     ]
    }
   ],
   "source": [
    "valid_losss, train_losses, valid_accus, train_accus = train_validation.continue_training(params['save_model_path'], params['epoch'], model, train_dataloader, eval_dataloader, optimizer, device, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
