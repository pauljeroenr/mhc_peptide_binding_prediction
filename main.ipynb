{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "from mhcflurry import Class1AffinityPredictor\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "from torch import nn \n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import metrics\n",
    "import data_transformation\n",
    "import train_validation\n",
    "import model_architecture\n",
    "import rank_model\n",
    "import utils\n",
    "import unittest\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_modules(module_test):\n",
    "    \"\"\"Run unittest in imported files\"\"\"\n",
    "    \n",
    "    suite = unittest.TestLoader().loadTestsFromModule(module_test)\n",
    "    unittest.TextTestRunner(verbosity=1).run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 17.098s\n",
      "\n",
      "OK\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.005s\n",
      "\n",
      "OK\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.102s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "testmodules = [data_transformation.data_class_test(), metrics.metrics_test(), utils.utils_test()]\n",
    "for test in testmodules:\n",
    "    test_modules(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 64,\n",
    "    'save_model_path': \"ResNet_small.chkpt\",\n",
    "    'epoch': 200,\n",
    "    'model': \"ResNet_small\",\n",
    "    'dropout': 0.2,\n",
    "    \"optimizer\": \"sgd\", #adam sgd\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"adam_vanilla\": True,\n",
    "    'momentum': 0.9,\n",
    "    'preproc': \"log\", #boxcox log\n",
    "    'weight_decay': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156996, 2, 34, 20)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c3e83c3ebfe0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m                                     dropout = params['dropout'])\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m \u001b[0mpytorch_total_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model parameters: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpytorch_total_params\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#data_class = data_transformation.data_transformation(path_data = \"/data/curated_training_data_no_mass_spec.csv\",\n",
    "#                                                     path_mhc = \"/data/aligned_mhc_dataset.csv\",\n",
    "#                                                     allele_name = None,\n",
    "#                                                     quant_data = True,\n",
    "#                                                     encoding = \"one-hot\")\n",
    "#\n",
    "#pep, mhc, target = data_class.__getitem__()\n",
    "#\n",
    "#pep = np.expand_dims(pep, axis=1)\n",
    "#mhc = np.expand_dims(mhc, axis=1)\n",
    "#inp = np.hstack((pep, mhc))\n",
    "#print(inp.shape)\n",
    "#\n",
    "#X_train, X_test, y_train, y_test = train_test_split(inp, target.T, test_size=0.2, random_state=42)\n",
    "data_class = data_transformation.data_transformation(path_data = \"/data/data_curated_20180219/curated_training_data_no_mass_spec_dbscan.csv\",\n",
    "                                                     path_mhc = \"/data/aligned_mhc_dataset.csv\",\n",
    "                                                     allele_name = None,\n",
    "                                                     quant_data = True,\n",
    "                                                     encoding = \"one-hot\",\n",
    "                                                     transformation = params['preproc'])\n",
    "\n",
    "\n",
    "pep, mhc, target, dbscan = data_class.__getitem__()\n",
    "\n",
    "if params['preproc'] == 'boxcox':\n",
    "    target = boxcox(target.flatten(), 0.055).reshape(-1, 1)\n",
    "else:\n",
    "    target = target.T\n",
    "pep = np.expand_dims(pep, axis=1)\n",
    "mhc = np.expand_dims(mhc, axis=1)\n",
    "inp = np.hstack((pep, mhc))\n",
    "print(inp.shape)\n",
    "\n",
    "np.random.seed(17) \n",
    "test_index = np.random.choice(np.where(dbscan.T == -1)[0],\n",
    "                              size = int(np.round(dbscan.T.shape[0] * 0.2)),\n",
    "                              replace = False)\n",
    "\n",
    "X_train = inp[~np.isin(np.arange(len(inp)), test_index)]\n",
    "X_test = inp[np.isin(np.arange(len(inp)), test_index)]\n",
    "y_train = target[~np.isin(np.arange(len(target)), test_index)]\n",
    "y_test = target[np.isin(np.arange(len(target)), test_index)]\n",
    "\n",
    "if params['preproc'] == 'boxcox':\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(y_train)\n",
    "    y_train = scaler.transform(y_train)\n",
    "    y_test = scaler.transform(y_test)\n",
    "\n",
    "if params['model'] == 'conv3x3':\n",
    "    model = model_architecture.conv3x3(inputchannel = np.size(X_train, 3),\n",
    "                                    L = np.size(X_train, 2),\n",
    "                                    dropout = params['dropout'],\n",
    "                                    dropoutearly = 0)#0.2)\n",
    "elif params['model'] == 'convnet':\n",
    "    model = model_architecture.convnet(inputchannel = np.size(X_train, 3),\n",
    "                                L = np.size(X_train, 2),\n",
    "                                dropout = params['dropout'])\n",
    "elif params['model'] == 'ResNet18':\n",
    "    model = model_architecture.ResNet(inputchannel = np.size(X_train, 3),\n",
    "                                    block = model_architecture.BasicBlock, \n",
    "                                    num_blocks = [2,2,2,2],\n",
    "                                    num_classes = 1,\n",
    "                                    dropout = params['dropout'])\n",
    "elif params['model'] == 'ResNet50':\n",
    "    model = model_architecture.ResNet(inputchannel = np.size(X_train, 3),\n",
    "                                    block = model_architecture.Bottleneck, \n",
    "                                    num_blocks = [3,4,6,3],\n",
    "                                    num_classes = 1,\n",
    "                                    dropout = params['dropout'])\n",
    "elif params['model'] == 'ResNet_small':\n",
    "    model = model_architecture.ResNet(inputchannel = np.size(X_train, 3),\n",
    "                                    block = model_architecture.BasicBlock, \n",
    "                                    num_blocks = [1,1,1,1],\n",
    "                                    num_classes = 1,\n",
    "                                    dropout = params['dropout'])\n",
    "  \n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Model parameters: \" + str(pytorch_total_params) )\n",
    "if torch.cuda.device_count() > 0:\n",
    "    print('Using GPU' + str(utils.pick_gpu_lowest_memory()))\n",
    "    device = torch.device('cuda:' + str(utils.pick_gpu_lowest_memory()))\n",
    "else:\n",
    "    print('Using CPU')\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "model = model.to(device)\n",
    "criterion = metrics.select_criterion('MSE')\n",
    "if params['optimizer'] == \"adam\":\n",
    "    if params['adam_vanilla']:\n",
    "        optimizer = optim.Adam(\n",
    "                      filter(lambda x: x.requires_grad, model.parameters()),\n",
    "                      lr = params['learning_rate'],\n",
    "                      weight_decay = params['weight_decay'])\n",
    "    else:\n",
    "        optimizer = optim.Adam(\n",
    "                      filter(lambda x: x.requires_grad, model.parameters()),\n",
    "                      lr = params['learning_rate'],\n",
    "                      betas=(0.9, 0.98),\n",
    "                      eps=1e-09,\n",
    "                      weight_decay = params['weight_decay'])    \n",
    "elif params['optimizer'] == \"sgd\":\n",
    "    optimizer = optim.SGD(\n",
    "                filter(lambda x: x.requires_grad, model.parameters()),\n",
    "                lr=params['learning_rate'], \n",
    "                momentum=params['momentum'],\n",
    "                weight_decay = params['weight_decay'])\n",
    "\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train))\n",
    "test_data = torch.utils.data.TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
    "                              batch_size = params['batch_size'],\n",
    "                              shuffle = True, \n",
    "                              drop_last = True)\n",
    "eval_dataloader = torch.utils.data.DataLoader(test_data,\n",
    "                              batch_size = params['batch_size'],\n",
    "                              shuffle = True,\n",
    "                              drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_losss, train_losses, valid_accus, train_accus, true_valid, pred_valid = train_validation.start_training(params['save_model_path'], params['epoch'], model,\n",
    "                                                                                                              train_dataloader, eval_dataloader, optimizer,\n",
    "                                                                                                              device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_losss, train_losses, valid_accus, train_accus, true_valid, pred_valid = train_validation.continue_training(params['save_model_path'], params['epoch'], model, \n",
    "                                                                                                                 train_dataloader, eval_dataloader, optimizer, \n",
    "                                                                                                                 device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_columns = ['id', 'Loss', 'Accuracy', 'Model', 'Dropout',\n",
    "               'Optimizer', 'Adam_vanilla', 'momentum', \n",
    "               'Learning_rate', 'Preprocess', 'Batch_size',\n",
    "               'Weight_decay']\n",
    "\n",
    "dict_data = []\n",
    "time_exp = round(time.time())\n",
    "for i in range(int(params['epoch'] / 5)):\n",
    "    dict_data.append({'id': str(time_exp) + '_' + str(i*5+1),\n",
    "                      'Loss': (valid_losss[i*5] / (np.max(y_test) - np.min(y_test))),\n",
    "                      'Accuracy': valid_accus[i*5], 'Model': params['model'], 'Dropout': params['dropout'],\n",
    "                      'Optimizer': params['optimizer'], 'Adam_vanilla': params['adam_vanilla'],\n",
    "                      'momentum': params['momentum'], 'Learning_rate': params['learning_rate'],\n",
    "                      'Preprocess': params['preproc'], 'Batch_size': params['batch_size'],\n",
    "                      'Weight_decay': params['weight_decay']})\n",
    "\n",
    "csv_file = \"experiment_log.csv\"\n",
    "if os.path.isfile(csv_file):\n",
    "    fileEmpty = os.stat(csv_file).st_size == 0\n",
    "else:\n",
    "    fileEmpty = True\n",
    "try:\n",
    "    with open(csv_file, 'a') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = csv_columns)\n",
    "        if fileEmpty:\n",
    "            writer.writeheader()  # file doesn't exist yet, write a header\n",
    "        for data in dict_data:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict new Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mhc(allele_name):\n",
    "\n",
    "    #data_class = data_transformation.data_transformation(path_data = \"/data/curated_training_data_no_mass_spec.csv\",\n",
    "    #                                                     path_mhc = \"/data/aligned_mhc_dataset.csv\",\n",
    "    #                                                     allele_name = None,\n",
    "    #                                                     quant_data = True,\n",
    "    #                                                     encoding = \"one-hot\")\n",
    "    #\n",
    "    #pep, mhc, target = data_class.__getitem__()\n",
    "    #\n",
    "    #pep = np.expand_dims(pep, axis=1)\n",
    "    #mhc = np.expand_dims(mhc, axis=1)\n",
    "    #inp = np.hstack((pep, mhc))\n",
    "    #print(inp.shape)\n",
    "    #\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(inp, target.T, test_size=0.2, random_state=42)\n",
    "    data_class = data_transformation.data_transformation(path_data = \"/data/test_data_all_allele.csv\",\n",
    "                                                         path_mhc = \"/data/aligned_mhc_dataset.csv\",\n",
    "                                                         allele_name = allele_name,\n",
    "                                                         quant_data = True,\n",
    "                                                         dbscan = False,\n",
    "                                                         encoding = \"one-hot\",\n",
    "                                                         transformation = params['preproc'])\n",
    "\n",
    "\n",
    "    pep, mhc, target = data_class.__getitem__()\n",
    "\n",
    "    if params['preproc'] == 'boxcox':\n",
    "        target = boxcox(target.flatten(), 0.055).reshape(-1, 1)\n",
    "    else:\n",
    "        target = target.T\n",
    "    pep = np.expand_dims(pep, axis=1)\n",
    "    mhc = np.expand_dims(mhc, axis=1)\n",
    "    inp = np.hstack((pep, mhc))\n",
    "    print(inp.shape)\n",
    "\n",
    "    if params['preproc'] == 'boxcox':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(y_train)\n",
    "        y_train = scaler.transform(y_train)\n",
    "        y_test = scaler.transform(y_test)\n",
    "\n",
    "    if params['model'] == 'conv3x3':\n",
    "        model = model_architecture.conv3x3(inputchannel = np.size(inp, 3),\n",
    "                                        L = np.size(inp, 2),\n",
    "                                        dropout = params['dropout'],\n",
    "                                        dropoutearly = 0)#0.2)\n",
    "    elif params['model'] == 'convnet':\n",
    "        model = model_architecture.convnet(inputchannel = np.size(inp, 3),\n",
    "                                    L = np.size(inp, 2),\n",
    "                                    dropout = params['dropout'])\n",
    "    elif params['model'] == 'ResNet18':\n",
    "        model = model_architecture.ResNet(inputchannel = np.size(inp, 3),\n",
    "                                        block = model_architecture.BasicBlock, \n",
    "                                        num_blocks = [2,2,2,2],\n",
    "                                        num_classes = 1,\n",
    "                                        dropout = params['dropout'])\n",
    "    elif params['model'] == 'ResNet50':\n",
    "        model = model_architecture.ResNet(inputchannel = np.size(inp, 3),\n",
    "                                        block = model_architecture.Bottleneck, \n",
    "                                        num_blocks = [3,4,6,3],\n",
    "                                        num_classes = 1,\n",
    "                                        dropout = params['dropout'])\n",
    "    elif params['model'] == 'ResNet_small':\n",
    "        model = model_architecture.ResNet(inputchannel = np.size(inp, 3),\n",
    "                                        block = model_architecture.BasicBlock, \n",
    "                                        num_blocks = [1,1,1,1],\n",
    "                                        num_classes = 1,\n",
    "                                        dropout = params['dropout'])\n",
    "\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"Model parameters: \" + str(pytorch_total_params) )\n",
    "    if torch.cuda.device_count() > 0:\n",
    "        print('Using GPU' + str(utils.pick_gpu_lowest_memory()))\n",
    "        device = torch.device('cuda:' + str(utils.pick_gpu_lowest_memory()))\n",
    "    else:\n",
    "        print('Using CPU')\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = metrics.select_criterion('MSE')\n",
    "    if params['optimizer'] == \"adam\":\n",
    "        if params['adam_vanilla']:\n",
    "            optimizer = optim.Adam(\n",
    "                          filter(lambda x: x.requires_grad, model.parameters()),\n",
    "                          lr = params['learning_rate'],\n",
    "                          weight_decay = params['weight_decay'])\n",
    "        else:\n",
    "            optimizer = optim.Adam(\n",
    "                          filter(lambda x: x.requires_grad, model.parameters()),\n",
    "                          lr = params['learning_rate'],\n",
    "                          betas=(0.9, 0.98),\n",
    "                          eps=1e-09,\n",
    "                          weight_decay = params['weight_decay'])    \n",
    "    elif params['optimizer'] == \"sgd\":\n",
    "        optimizer = optim.SGD(\n",
    "                    filter(lambda x: x.requires_grad, model.parameters()),\n",
    "                    lr=params['learning_rate'], \n",
    "                    momentum=params['momentum'],\n",
    "                    weight_decay = params['weight_decay'])\n",
    "\n",
    "\n",
    "    test_data = torch.utils.data.TensorDataset(torch.from_numpy(inp).float(), torch.from_numpy(target))\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_data,\n",
    "                              batch_size = 1,\n",
    "                              shuffle = False,\n",
    "                              drop_last = False)\n",
    "\n",
    "    a, b = train_validation.prediction_only(params['save_model_path'], model, test_dataloader, optimizer, device, criterion)\n",
    "    out_pred = np.concatenate(a).ravel()\n",
    "    out_true = np.concatenate(b).ravel()\n",
    "    mymodel_out = pd.DataFrame(list(zip(out_pred, out_true)), columns =['pred', 'true']).apply(lambda y: rank_model.reverse_log_transformation(y))\n",
    "\n",
    "    flurry_data = pd.read_csv(\"C:/Users/paul_/OneDrive/Desktop/master-thesis/data/test_data_all_allele.csv\")\n",
    "    mask = (flurry_data['peptide'].str.len() >= 8) & (flurry_data['peptide'].str.len() <= 15)\n",
    "    flurry_data = flurry_data.loc[mask]\n",
    "    flurry_out = rank_model.mhcflurry_test(flurry_data, allele_name)\n",
    "    \n",
    "    error_dict_my, len_dict_my = rank_model.root_mean_squared(mymodel_out, allele_name, \"my\")\n",
    "    error_dict_flurry, len_dict_flurry = rank_model.root_mean_squared(flurry_out, allele_name, \"flurry\")\n",
    "    return(error_dict_my, len_dict_my, error_dict_flurry, len_dict_flurry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HLA-A*03:01\n",
      "(10, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.005728610356648763 min\n",
      "HLA-A*24:02\n",
      "(8, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.005364545186360677 min\n",
      "HLA-A*68:01\n",
      "(2, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.0018236080805460611 min\n",
      "HLA-A*02:05\n",
      "(2, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.0015625874201456705 min\n",
      "H-2-Kb\n",
      "(49, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.022916825612386067 min\n",
      "HLA-B*51:01\n",
      "(1, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.0007806936899820964 min\n",
      "HLA-A*11:01\n",
      "(8, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.0039502104123433435 min\n",
      "HLA-A*02:01\n",
      "(63, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.047503928343454994 min\n",
      "HLA-A*68:02\n",
      "(2, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.0040002028147379555 min\n",
      "HLA-B*44:02\n",
      "(4, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.004664186636606852 min\n",
      "HLA-A*01:01\n",
      "(11, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.008915277322133382 min\n",
      "HLA-B*07:02\n",
      "(12, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.009082313378651936 min\n",
      "HLA-B*35:01\n",
      "(1, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.0014131704966227213 min\n",
      "HLA-B*44:03\n",
      "(4, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.002997310956319173 min\n",
      "H-2-Db\n",
      "(62, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.035086750984191895 min\n",
      "HLA-B*15:01\n",
      "(5, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.0040855805079142255 min\n",
      "HLA-B*38:01\n",
      "(2, 2, 34, 20)\n",
      "Model parameters: 4919937\n",
      "Using CPU\n",
      "Checkpoint found and loaded - Predict values\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Test) Elapse: 0.0014952460924784342 min\n"
     ]
    }
   ],
   "source": [
    "# More MHCs are supported in my model\n",
    "# No restriction for length of peptides -- mhcflurry 8 - 15 len\n",
    "\n",
    "params['model'] = \"ResNet_small\"\n",
    "params['save_model_path'] = \"ResNet_small025dropout.chkpt\"\n",
    "\n",
    "# Compare only MHC supported in mhcflurry\n",
    "allele_names = pd.read_csv(\"C:/Users/paul_/OneDrive/Desktop/master-thesis/data/test_data_all_allele.csv\").allele.unique()\n",
    "predictor = Class1AffinityPredictor.load()\n",
    "\n",
    "mhc_names = list(set(allele_names.tolist()) & set(predictor.supported_alleles))\n",
    "combined_dict = {}\n",
    "len_dict = {}\n",
    "for i in mhc_names:\n",
    "    print(i)\n",
    "    error_my, len_my, error_flurry, len_flurry = predict_mhc(i)\n",
    "    len_dict.update(len_my)\n",
    "    len_dict.update(len_flurry)\n",
    "    combined_dict.update(error_my)\n",
    "    combined_dict.update(error_flurry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HLA-A*03:01my': 6628.023363915202,\n",
       " 'HLA-A*03:01flurry': 467.068469477591,\n",
       " 'HLA-A*24:02my': 10355.625933065807,\n",
       " 'HLA-A*24:02flurry': 5708.133603554634,\n",
       " 'HLA-A*68:01my': 29.87179134993718,\n",
       " 'HLA-A*68:01flurry': 17.575974910700896,\n",
       " 'HLA-A*02:05my': 26.069356869003535,\n",
       " 'HLA-A*02:05flurry': 148.6809021300337,\n",
       " 'H-2-Kbmy': 3611.8441815086994,\n",
       " 'H-2-Kbflurry': 5670.493803096738,\n",
       " 'HLA-B*51:01my': 1190.9107443561595,\n",
       " 'HLA-B*51:01flurry': 260.3452569976687,\n",
       " 'HLA-A*11:01my': 7274.252153930705,\n",
       " 'HLA-A*11:01flurry': 7630.797311378845,\n",
       " 'HLA-A*02:01my': 26141.516940120844,\n",
       " 'HLA-A*02:01flurry': 26411.98437729448,\n",
       " 'HLA-A*68:02my': 29.510797043027925,\n",
       " 'HLA-A*68:02flurry': 24.83060501704868,\n",
       " 'HLA-B*44:02my': 453.94168812789644,\n",
       " 'HLA-B*44:02flurry': 181.76560422029905,\n",
       " 'HLA-A*01:01my': 9471.208705460185,\n",
       " 'HLA-A*01:01flurry': 10153.670854486432,\n",
       " 'HLA-B*07:02my': 8169.236512904359,\n",
       " 'HLA-B*07:02flurry': 9349.510131293062,\n",
       " 'HLA-B*35:01my': 25574.300510184028,\n",
       " 'HLA-B*35:01flurry': 27621.23170132551,\n",
       " 'HLA-B*44:03my': 1060.9829309934064,\n",
       " 'HLA-B*44:03flurry': 2580.8765609400093,\n",
       " 'H-2-Dbmy': 8919.73138612962,\n",
       " 'H-2-Dbflurry': 10177.850070397904,\n",
       " 'HLA-B*15:01my': 30209.243733110245,\n",
       " 'HLA-B*15:01flurry': 24822.65986441854,\n",
       " 'HLA-B*38:01my': 2173.9218870428076,\n",
       " 'HLA-B*38:01flurry': 2152.7436869001313}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HLA-A*03:01my': 10,\n",
       " 'HLA-A*03:01flurry': 10,\n",
       " 'HLA-A*24:02my': 8,\n",
       " 'HLA-A*24:02flurry': 8,\n",
       " 'HLA-A*68:01my': 2,\n",
       " 'HLA-A*68:01flurry': 2,\n",
       " 'HLA-A*02:05my': 2,\n",
       " 'HLA-A*02:05flurry': 2,\n",
       " 'H-2-Kbmy': 49,\n",
       " 'H-2-Kbflurry': 48,\n",
       " 'HLA-B*51:01my': 1,\n",
       " 'HLA-B*51:01flurry': 1,\n",
       " 'HLA-A*11:01my': 8,\n",
       " 'HLA-A*11:01flurry': 8,\n",
       " 'HLA-A*02:01my': 63,\n",
       " 'HLA-A*02:01flurry': 63,\n",
       " 'HLA-A*68:02my': 2,\n",
       " 'HLA-A*68:02flurry': 2,\n",
       " 'HLA-B*44:02my': 4,\n",
       " 'HLA-B*44:02flurry': 4,\n",
       " 'HLA-A*01:01my': 11,\n",
       " 'HLA-A*01:01flurry': 11,\n",
       " 'HLA-B*07:02my': 12,\n",
       " 'HLA-B*07:02flurry': 12,\n",
       " 'HLA-B*35:01my': 1,\n",
       " 'HLA-B*35:01flurry': 1,\n",
       " 'HLA-B*44:03my': 4,\n",
       " 'HLA-B*44:03flurry': 4,\n",
       " 'H-2-Dbmy': 62,\n",
       " 'H-2-Dbflurry': 61,\n",
       " 'HLA-B*15:01my': 5,\n",
       " 'HLA-B*15:01flurry': 5,\n",
       " 'HLA-B*38:01my': 2,\n",
       " 'HLA-B*38:01flurry': 2}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12092.855879564228\n",
      "8312.952506830115\n"
     ]
    }
   ],
   "source": [
    "weighted_a = np.average(a = np.array([value for key, value in combined_dict.items() if 'my' in key.lower()]),\n",
    "                        weights = np.array([value for key, value in len_dict.items() if 'my' in key.lower()]))\n",
    "a = np.mean(a = np.array([value for key, value in combined_dict.items() if 'my' in key.lower()]))\n",
    "print(weighted_a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12540.931610166197\n",
      "7845.8952222258595\n"
     ]
    }
   ],
   "source": [
    "weighted_b = np.average(a = np.array([value for key, value in combined_dict.items() if 'flurry' in key.lower()]),\n",
    "                        weights = np.array([value for key, value in len_dict.items() if 'flurry' in key.lower()]))\n",
    "b = np.mean([value for key, value in combined_dict.items() if 'flurry' in key.lower()])\n",
    "print(weighted_b)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.952887100520732\n",
      "-3.572906260319142\n"
     ]
    }
   ],
   "source": [
    "print((a/b - 1) * 100)\n",
    "print((weighted_a/weighted_b - 1) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8685909777161993"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet_small 200e 0.25 dropout\n",
    "(a/b - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.5294610188582154"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet_small 75e 0.25 dropout\n",
    "(a/b - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.355991318651521"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet_small 60e 0.25 dropout\n",
    "(a/b - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.645966507406185"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet_small 40e 0.25 dropout\n",
    "(a/b - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.516955714370948"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConvNet 200e\n",
    "(a/b - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.914762463525536"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConvNet 110e\n",
    "(a/b - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.46196891540847"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConvNet 50e\n",
    "(a/b - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.102533941685026"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet18 - altes Splitting\n",
    "(a/b - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.3314228440623697"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet_small 160 Epoch\n",
    "(a/b - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.276630118220703"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No fcking clue conv3x3???\n",
    "(a/b - 1) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
