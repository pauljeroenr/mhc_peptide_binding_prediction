{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from metrics.ipynb\n",
      "importing Jupyter notebook from data_transformation.ipynb\n",
      "importing Jupyter notebook from train_validation.ipynb\n",
      "importing Jupyter notebook from model_architecture.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import metrics\n",
    "import data_transformation\n",
    "import train_validation\n",
    "import model_architecture\n",
    "import unittest\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import math\n",
    "from random import shuffle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "from torch import nn \n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "import itertools\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_modules(module_test):\n",
    "    suite = unittest.TestLoader().loadTestsFromModule(module_test)\n",
    "    unittest.TextTestRunner(verbosity=1).run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.006s\n",
      "\n",
      "OK\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.039s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "testmodules = [data_transformation.TestNotebook(), metrics.metrics_test()]\n",
    "output_test = []\n",
    "for test in testmodules:\n",
    "    test_modules(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 32,\n",
    "    'save_model_path': \"test.chkpt\",\n",
    "    'epoch': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 217364\n",
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "X_train = np.random.randint(0, 2, (320, 30, 20))\n",
    "y_train = np.random.uniform(0, 1, (320, 1))\n",
    "X_test = np.random.randint(0, 2, (80, 30, 20))\n",
    "y_test = np.random.uniform(0, 1, (80, 1))\n",
    "#make dataset? or in data_transformation\n",
    "model = model_architecture.convnet(np.size(X_train, 1), np.size(X_train, 2))\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Model parameters: \"+str(pytorch_total_params) )\n",
    "if torch.cuda.device_count() > 0:\n",
    "    print('Using GPU' + str(pick_gpu_lowest_memory()))\n",
    "    device = 'cuda:'+str(pick_gpu_lowest_memory())\n",
    "else:\n",
    "    print('Using CPU')\n",
    "    device = 'cpu'\n",
    "model = model.to(device)\n",
    "criterion = metrics.select_criterion('MSE')\n",
    "optimizer = optim.Adam(\n",
    "        filter(lambda x: x.requires_grad, model.parameters()),\n",
    "        betas=(0.9, 0.98), eps=1e-09, weight_decay = 0.0)\n",
    "\n",
    "\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train))\n",
    "test_data = torch.utils.data.TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
    "                              batch_size = params['batch_size'],\n",
    "                              shuffle = True, \n",
    "                              drop_last = True)\n",
    "eval_dataloader = torch.utils.data.DataLoader(test_data,\n",
    "                              batch_size = params['batch_size'],\n",
    "                              shuffle = True,\n",
    "                              drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch 0 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training)   ppl: 0.2609993055462837, Accuracy: 0.019538216517165426, elapse: 0.15719339450200398 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Validation) ppl: 0.2308492213487625, Accuracy: 0.03407444598918856, elapse: 0.011979877948760986 min\n",
      "[ Epoch 1 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training)   ppl: 0.17661265581846236, Accuracy: 0.1370466474210063, elapse: 0.1650582234064738 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Validation) ppl: 0.10538044944405556, Accuracy: -0.028638279819761588, elapse: 0.012109478314717611 min\n"
     ]
    }
   ],
   "source": [
    "valid_losss, train_losses, valid_accus, train_accus = train_validation.start_training(params['save_model_path'], params['epoch'], model,\n",
    "                                                                                      train_dataloader, eval_dataloader, optimizer,\n",
    "                                                                                      device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint found and loaded - Resuming training\n",
      "[ Epoch 2 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training)   ppl: 0.14249686151742935, Accuracy: 0.20002837834907883, elapse: 0.18731647729873657 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Validation) ppl: 0.10182568430900574, Accuracy: -0.05117330838421105, elapse: 0.012834278742472331 min\n",
      "[ Epoch 3 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Training)   ppl: 0.10645390748977661, Accuracy: 0.31931252712171926, elapse: 0.22762589454650878 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - (Validation) ppl: 0.08408648520708084, Accuracy: 0.10670699137871208, elapse: 0.019465947151184083 min\n"
     ]
    }
   ],
   "source": [
    "valid_losss, train_losses, valid_accus, train_accus = train_validation.continue_training(params['save_model_path'], params['epoch'], model, train_dataloader, eval_dataloader, optimizer, device, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
